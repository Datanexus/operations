#!/usr/bin/env ansible-playbook
# (c) 2019 DataNexus Inc.  All Rights Reserved.
#
#
---
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | discovering all relevant nodes
  hosts: localhost
  tasks:
    - ec2_instance_facts:
        region: "{{ region }}"
        filters:
          instance-state-name: running
          "tag:Application": kafka_connect
          "tag:Domain": "{{ domain }}"
          "tag:Project": "{{ project }}"
          "tag:Tenant": "{{ tenant }}"
          "tag:Cluster": "{{ cluster | default ('a') }}"
      register: connect_instances
      when:
        - groups['kafka_connect'] is not defined
        - cloud == 'aws'
        
    - name: OPERATIONS OVERLAY (KAFKA CONNECT) | building kafka connect host group
      add_host: hostname="{{ item }}" groupname=kafka_connect ansible_ssh_private_key_file="{{ key_path }}/{{ cloud }}-{{ region }}-{{ project }}-{{ application }}-{{ domain }}-private-key.pem"
      with_items: "{{ connect_instances.instances | map(attribute='private_ip_address') | list }}"
      when:
        - connect_instances.instances is defined
        - connect_instances.instances | length > 0
    
    - ec2_instance_facts:
        region: "{{ region }}"
        filters:
          instance-state-name: running
          "tag:Application": elasticsearch
          "tag:Domain": "{{ domain }}"
          "tag:Project": "{{ project }}"
          "tag:Tenant": "{{ tenant }}"
          "tag:Cluster": "{{ cluster | default ('a') }}"
      register: elasticsearch_instances
      when:
        - groups['elasticsearch'] is not defined
        - cloud == 'aws'
    
    - name: OPERATIONS OVERLAY (KAFKA CONNECT) | building elasticsearch host group
      add_host: hostname="{{ item }}" groupname=elasticsearch ansible_ssh_private_key_file="{{ key_path }}/{{ cloud }}-{{ region }}-{{ project }}-{{ application }}-{{ domain }}-private-key.pem"
      with_items: "{{ elasticsearch_instances.instances|map(attribute='private_ip_address')|list }}"
      when:
        - elasticsearch_instances.instances is defined
        - elasticsearch_instances.instances | length > 0

# this is necessary before we build host groups from the ansible server
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | discovering source broker facts
  hosts: broker_source
  tasks:
    - setup:

# this is necessary before we build host groups from the ansible server
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | discovering elasticsearch facts
  hosts: broker_destination
  tasks:
    - setup:

- name: OPERATIONS OVERLAY (KAFKA CONNECT) | building source and destination broker public internal host groups
  hosts: localhost
  gather_facts: no
  tasks:
    # eth0 is the data plane in a single interface system
    - name: KAFKA OVERLAY | building eth0 broker source host group
      add_host: hostname="{{ hostvars[item].ansible_eth0.ipv4.address }}" groupname=broker_source_public
      with_items: "{{ groups['broker_source'] }}"
      when:
        - "'broker_source' in groups | default([])"
        - hostvars[item].ansible_eth1 is not defined

    # eth1 is the dataplane in a multi interface system
    - name: KAFKA OVERLAY | building eth1 broker source host group
      add_host: hostname="{{ hostvars[item].ansible_eth1.ipv4.address }}" groupname=broker_source_public
      with_items: "{{ groups['broker_source'] }}"
      when:
        - "'broker_source' in groups | default([])"
        - hostvars[item].ansible_eth1 is defined
    
    # eth0 is the data plane in a single interface system
    - name: KAFKA OVERLAY | building eth0 broker destination host group
      add_host: hostname="{{ hostvars[item].ansible_eth0.ipv4.address }}" groupname=broker_destination_public
      with_items: "{{ groups['broker_destination'] }}"
      when:
        - "'broker_destination' in groups | default([])"
        - hostvars[item].ansible_eth1 is not defined

    # eth1 is the dataplane in a multi interface system
    - name: KAFKA OVERLAY | building eth1 broker destination host group
      add_host: hostname="{{ hostvars[item].ansible_eth1.ipv4.address }}" groupname=broker_destination_public
      with_items: "{{ groups['broker_destination'] }}"
      when:
        - "'broker_destination' in groups | default([])"
        - hostvars[item].ansible_eth1 is defined
      
# this is necessary before we build host groups from the ansible server
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | discovering elasticsearch facts
  hosts: elasticsearch
  tasks:
    - setup:

- name: OPERATIONS OVERLAY (KAFKA CONNECT) | building elasticsearch public internal host group
  hosts: localhost
  gather_facts: no
  tasks:
    # eth0 is the data plane in a single interface system
    - name: KAFKA OVERLAY | building eth0 elasticsearch host group
      add_host: hostname="{{ hostvars[item].ansible_eth0.ipv4.address }}" groupname=elasticsearch_public
      with_items: "{{ groups['elasticsearch'] }}"
      when:
        - "'elasticsearch' in groups | default([])"
        - hostvars[item].ansible_eth1 is not defined

    # eth1 is the dataplane in a multi interface system
    - name: KAFKA OVERLAY | building eth1 elasticsearch host group
      add_host: hostname="{{ hostvars[item].ansible_eth1.ipv4.address }}" groupname=elasticsearch_public
      with_items: "{{ groups['elasticsearch'] }}"
      when:
        - "'elasticsearch' in groups | default([])"
        - hostvars[item].ansible_eth1 is defined
        
# this is necessary before we build host groups from the ansible server
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | discovering connect facts
  hosts: kafka_connect
  tasks:
    - setup:

- name: OPERATIONS OVERLAY (KAFKA CONNECT) | building kafka connect public internal host group
  hosts: localhost
  gather_facts: no
  tasks:
    # eth0 is the data plane in a single interface system
    - name: KAFKA OVERLAY | building eth0 connect host group
      add_host: hostname="{{ hostvars[item].ansible_eth0.ipv4.address }}" groupname=connect_public
      with_items: "{{ groups['kafka_connect'] }}"
      when:
        - "'kafka_connect' in groups | default([])"
        - hostvars[item].ansible_eth1 is not defined

    # eth1 is the dataplane in a multi interface system
    - name: KAFKA OVERLAY | building eth1 connect host group
      add_host: hostname="{{ hostvars[item].ansible_eth1.ipv4.address }}" groupname=connect_public
      with_items: "{{ groups['kafka_connect'] }}"
      when:
        - "'kafka_connect' in groups | default([])"
        - hostvars[item].ansible_eth1 is defined

- name: OPERATIONS OVERLAY (KAFKA CONNECT) | configuring connectors
  hosts: kafka_connect
  vars_files:
    - "{{ tenant_config_path }}/config/site.yml"
    - "{{ tenant_config_path }}/config/applications/shaw.yml"
    - "{{ tenant_config_path }}/config/applications/kafka.yml"
    - "{{ tenant_config_path }}/config/applications/connect.yml"
    - "{{ tenant_config_path }}/config/applications/confluent.yml"
    - "{{ tenant_config_path }}/config/applications/apache.yml"
  gather_facts: yes
  tasks:
    - import_role:
        name: connect
        
# since we run distributed connectors, we only need register on a single host
- name: OPERATIONS OVERLAY (KAFKA CONNECT) | configuring connectors
  hosts: kafka_connect[0]
  vars_files:
    - "{{ tenant_config_path }}/config/site.yml"
    - "{{ tenant_config_path }}/config/applications/shaw.yml"
    - "{{ tenant_config_path }}/config/applications/kafka.yml"
    - "{{ tenant_config_path }}/config/applications/connect.yml"
    - "{{ tenant_config_path }}/config/applications/confluent.yml"
    - "{{ tenant_config_path }}/config/applications/apache.yml"
  gather_facts: yes
  tasks:
    - include_role:
        name: connect
        tasks_from: run-elasticsearch
    
    - include_role:
        name: connect
        tasks_from: run-tenant
    
    - include_role:
        name: connect
        tasks_from: run-replicator
